{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/09 08:43:00 WARN Utils: Your hostname, codespaces-3e9f4e resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
      "23/05/09 08:43:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/09 08:43:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://2ca2e260-c899-4c33-ad60-8ea325e96bfd.internal.cloudapp.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FordGoBike</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdb54f346d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType, StringType\n",
    "\n",
    "spark=SparkSession.builder.appName('FordGoBike').getOrCreate()\n",
    "spark\n",
    "# https://www.kaggle.com/code/priyankabnl/fordgobike-trip-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path=\"/workspaces/develhope-Data5-Team3/Data/2017-fordgobike-tripdataa.csv\"\n",
    "df_pyspark=spark.read.csv(path,header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- start time hour: integer (nullable = true)\n",
      " |-- start time minute: integer (nullable = true)\n",
      " |-- start time seconds: integer (nullable = true)\n",
      " |-- start_am_pm: string (nullable = true)\n",
      " |-- end_time: string (nullable = true)\n",
      " |-- end_time hour: integer (nullable = true)\n",
      " |-- end_time minute: integer (nullable = true)\n",
      " |-- end_time seconds: integer (nullable = true)\n",
      " |-- end_am_pm: string (nullable = true)\n",
      " |-- start_station_id: integer (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: float (nullable = true)\n",
      " |-- start_station_longitude: float (nullable = true)\n",
      " |-- end_station_id: integer (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: float (nullable = true)\n",
      " |-- end_station_longitude: float (nullable = true)\n",
      " |-- bike_id: integer (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- member_birth_year: integer (nullable = true)\n",
      " |-- member_gender: string (nullable = true)\n",
      " |-- pyment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=df_pyspark.withColumn('start_station_longitude',F.col('start_station_longitude').cast(FloatType()))\\\n",
    "    .withColumn('start_station_latitude',F.col('start_station_latitude').cast(FloatType()))\\\n",
    "    .withColumn('end_station_latitude',F.col('end_station_latitude').cast(FloatType()))\\\n",
    "    .withColumn('end_station_longitude',F.col('end_station_longitude').cast(FloatType()))\n",
    "df_pyspark=df_pyspark.withColumnRenamed('_c4','start_am_pm').withColumnRenamed('_c9','end_am_pm')\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark= df_pyspark.withColumn('start time hour',F.when(df_pyspark['start_am_pm']=='PM',df_pyspark[\"start time hour\"]+12).otherwise(df_pyspark[\"start time hour\"]))\n",
    "df_pyspark= df_pyspark.withColumn('start time hour',F.when(df_pyspark['start time hour']==24,12).otherwise(df_pyspark[\"start time hour\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark= df_pyspark.withColumn('end_time hour',F.when(df_pyspark['end_am_pm']=='PM',df_pyspark[\"end_time hour\"]+12).otherwise(df_pyspark[\"end_time hour\"]))\n",
    "df_pyspark= df_pyspark.withColumn('end_time hour',F.when(df_pyspark['end_time hour']==24,12).otherwise(df_pyspark[\"end_time hour\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.filter(F.col('end_time hour')==24).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing 1-digit values \n",
    "df_pyspark=df_pyspark.withColumn('start time hour',F.lpad(F.col('start time hour'),2,'0'))\\\n",
    "    .withColumn('start time minute',F.lpad(F.col('start time minute'),2,'0'))\\\n",
    "    .withColumn('start time seconds',F.lpad(F.col('start time seconds'),2,'0'))\\\n",
    "    .withColumn('end_time hour',F.lpad(F.col('end_time hour'),2,'0'))\\\n",
    "    .withColumn('end_time minute',F.lpad(F.col('end_time minute'),2,'0'))\\\n",
    "    .withColumn('end_time seconds',F.lpad(F.col('end_time seconds'),2,'0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating start time and end time columns with timestamp for easy comparison\n",
    "df_pyspark=df_pyspark.withColumn('start time',F.to_timestamp(F.concat_ws(':',F.lpad(F.col('start time hour'),2,'0'),F.lpad(F.col('start time minute'),2,'0'),F.lpad(F.col('start time seconds'),2,'0'))))\n",
    "df_pyspark=df_pyspark.withColumn('end time',F.to_timestamp(F.concat_ws(':',F.lpad(F.col('end_time hour'),2,'0'),F.lpad(F.col('end_time minute'),2,'0'),F.lpad(F.col('end_time seconds'),2,'0'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swapping end time and start time values if start time > end time\n",
    "df_pyspark=df_pyspark.withColumn('end time',F.when(df_pyspark['end time']<df_pyspark['start time'], df_pyspark['start time'])\\\n",
    "                                 .otherwise(df_pyspark['end time']))\n",
    "df_pyspark=df_pyspark.withColumn('start time',F.when(df_pyspark['end time']==df_pyspark['start time'], \n",
    "                                                     F.to_timestamp(F.concat_ws(':','end_time hour','end_time minute','end_time seconds')))\\\n",
    "                                 .otherwise(df_pyspark['start time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pyspark=df_pyspark.withColumn('start_time',F.concat_ws(':',F.lpad(F.hour(F.col('start time')),2,'0'),F.lapd(F.minute(F.col('start time')),2,'0'),F.lapd(F.second(F.col('start time')),2,'0')))#\\\n",
    "    #.withColumn('end_time',F.concat_ws(':',F.lpad(F.hour('end time'),2,'0'),F.lpad(F.minute('end time'),2,'0'),F.lpad(F.second('end time'),2,'0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.withColumn('start_time',df_pyspark['start time']).withColumn('end_time',df_pyspark['end time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+-------------------+---------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+-------+----------+-----------------+-------------+-----------+\n",
      "|         start_time|start_am_pm|           end_time|end_am_pm|start_station_id|  start_station_name|start_station_latitude|start_station_longitude|end_station_id|    end_station_name|end_station_latitude|end_station_longitude|bike_id| user_type|member_birth_year|member_gender|     pyment|\n",
      "+-------------------+-----------+-------------------+---------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+-------+----------+-----------------+-------------+-----------+\n",
      "|2023-05-09 15:12:50|         PM|2023-05-09 16:57:40|       PM|              74|Laguna St at Haye...|             37.776436|             -122.42625|            43|San Francisco Pub...|           37.778767|           -122.41593|     96|  Customer|             1987|         Male|credit card|\n",
      "|2023-05-09 13:49:56|         PM|2023-05-09 15:56:35|       PM|             284|Yerba Buena Cente...|             37.784874|             -122.40088|            96|Dolores St at 15t...|            37.76621|           -122.42661|     88|  Customer|             1965|       Female|credit card|\n",
      "|2023-05-09 11:28:37|         PM|2023-05-09 22:45:48|       AM|             245|Downtown Berkeley...|             37.870346|             -122.26776|           245|Downtown Berkeley...|           37.870346|           -122.26776|   1094|  Customer|             null|         null|credit card|\n",
      "|2023-05-09 10:47:24|         PM|2023-05-09 17:31:11|       AM|              60|8th St at Ringold St|              37.77452|             -122.40945|             5|Powell St BART St...|             37.7839|           -122.40845|   2831|  Customer|             null|         null|credit card|\n",
      "|2023-05-09 02:29:58|         PM|2023-05-09 14:23:14|       AM|             239|Bancroft Way at T...|             37.868813|            -122.258766|           247|Fulton St at Banc...|            37.86779|            -122.2659|   3167|Subscriber|             1997|       Female| app wallet|\n",
      "|2023-05-09 01:24:47|         PM|2023-05-09 22:51:01|       AM|              30|San Francisco Cal...|               37.7766|             -122.39528|            30|San Francisco Cal...|             37.7766|           -122.39528|   1487|  Customer|             null|         null| app wallet|\n",
      "|2023-05-09 01:04:36|         PM|2023-05-09 23:49:28|       AM|             259|Addison St at Fou...|              37.86625|             -122.29937|           259|Addison St at Fou...|            37.86625|           -122.29937|   3539|  Customer|             1991|       Female| app wallet|\n",
      "|2023-05-09 12:58:51|         PM|2023-05-09 23:46:37|       AM|             284|Yerba Buena Cente...|             37.784874|             -122.40088|           284|Yerba Buena Cente...|           37.784874|           -122.40088|   1503|  Customer|             null|         null| app wallet|\n",
      "|2023-05-09 12:46:18|         PM|2023-05-09 23:37:08|       AM|              20|Mechanics Monumen...|               37.7913|             -122.39905|            20|Mechanics Monumen...|             37.7913|           -122.39905|   3125|  Customer|             null|         null| app wallet|\n",
      "|2023-05-09 12:46:17|         PM|2023-05-09 23:35:38|       AM|              20|Mechanics Monumen...|               37.7913|             -122.39905|            20|Mechanics Monumen...|             37.7913|           -122.39905|   2543|  Customer|             null|         null| app wallet|\n",
      "|2023-05-09 12:41:25|         PM|2023-05-09 23:46:32|       AM|             284|Yerba Buena Cente...|             37.784874|             -122.40088|            22|Howard St at Beal...|           37.789757|          -122.394646|   3058|  Customer|             null|         null|credit card|\n",
      "|2023-05-09 12:41:10|         PM|2023-05-09 23:48:12|       AM|             284|Yerba Buena Cente...|             37.784874|             -122.40088|            22|Howard St at Beal...|           37.789757|          -122.394646|   3197|  Customer|             null|         null| app wallet|\n",
      "|2023-05-09 12:29:19|         PM|2023-05-09 23:52:56|       AM|              67|San Francisco Cal...|             37.776638|             -122.39552|            24|Spear St at Folso...|           37.789677|           -122.39043|   2311|Subscriber|             1990|         Male|credit card|\n",
      "|2023-05-09 12:29:07|         PM|2023-05-09 23:52:56|       AM|              67|San Francisco Cal...|             37.776638|             -122.39552|            24|Spear St at Folso...|           37.789677|           -122.39043|   3717|Subscriber|             1990|         Male| app wallet|\n",
      "|2023-05-09 12:20:21|         PM|2023-05-09 23:35:23|       AM|              66|3rd St at Townsen...|              37.77874|             -122.39274|            23|The Embarcadero a...|           37.791466|           -122.39104|   3452|  Customer|             null|         null|credit card|\n",
      "|2023-05-09 12:19:23|         PM|2023-05-09 23:53:39|       AM|              14|Clay St at Batter...|             37.795002|             -122.39997|            27|Beale St at Harri...|            37.78806|           -122.39187|    558|Subscriber|             1980|       Female|credit card|\n",
      "|2023-05-09 12:19:14|         PM|2023-05-09 23:54:40|       AM|              14|Clay St at Batter...|             37.795002|             -122.39997|            27|Beale St at Harri...|            37.78806|           -122.39187|   3646|Subscriber|             1979|         Male| app wallet|\n",
      "|2023-05-09 12:18:27|         PM|2023-05-09 23:55:10|       AM|              78| Folsom St at 9th St|             37.773716|            -122.411644|            15|San Francisco Fer...|            37.79539|            -122.3942|   1667|  Customer|             null|         null| app wallet|\n",
      "|2023-05-09 12:18:22|         PM|2023-05-09 23:52:49|       AM|              78| Folsom St at 9th St|             37.773716|            -122.411644|            15|San Francisco Fer...|            37.79539|            -122.3942|   3114|Subscriber|             1988|        Other| app wallet|\n",
      "|2023-05-09 12:06:50|         PM|2023-05-09 23:46:34|       AM|               4|Cyril Magnin St a...|              37.78588|             -122.40891|           123|Folsom St at 19th St|           37.760593|           -122.41482|   1473|Subscriber|             1971|         Male|credit card|\n",
      "+-------------------+-----------+-------------------+---------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+-------+----------+-----------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/09 08:45:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: start time hour, start time minute, start time seconds, , end_time hour, end_time minute, end_time seconds, , start_station_id, start_station_name, start_station_latitude, start_station_longitude, end_station_id, end_station_name, end_station_latitude, end_station_longitude, bike_id, user_type, member_birth_year, member_gender, pyment\n",
      " Schema: start time hour, start time minute, start time seconds, _c4, end_time hour, end_time minute, end_time seconds, _c9, start_station_id, start_station_name, start_station_latitude, start_station_longitude, end_station_id, end_station_name, end_station_latitude, end_station_longitude, bike_id, user_type, member_birth_year, member_gender, pyment\n",
      "Expected: _c4 but found: \n",
      "CSV file: file:///workspaces/develhope-Data5-Team3/Data/2017-fordgobike-tripdataa.csv\n"
     ]
    }
   ],
   "source": [
    "#Dropping 'start time' and 'end time' columns\n",
    "df_pyspark=df_pyspark.drop(*['start time','end time','start time hour',\n",
    " 'start time minute',\n",
    " 'start time seconds',\n",
    " 'end_time hour',\n",
    " 'end_time minute',\n",
    " 'end_time seconds',])\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting haversine\n",
      "  Downloading haversine-2.8.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine\n",
    "\n",
    "def haversine_f(lat1, lon1, lat2, lon2):\n",
    "    return haversine( (lat1, lon1), (lat2, lon2),unit='m',normalize=True )\n",
    "\n",
    "haversine_udf = F.udf(haversine_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate haversine distance(Onur)\n",
    "df_pyspark=df_pyspark.withColumn('haversine_distance', \n",
    "                    haversine_udf(F.col('start_station_latitude'), F.col('start_station_longitude'), \n",
    "                                  F.col('end_station_latitude'), F.col('end_station_longitude'))\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate haversine distance in meters(Uros)\n",
    "df_pyspark=df_pyspark.withColumn('haversine_distance',\n",
    "                                 haversine_udf('start_station_latitude', \n",
    "                                               'start_station_longitude', \n",
    "                                               'end_station_latitude', \n",
    "                                               'end_station_longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- start_am_pm: string (nullable = true)\n",
      " |-- end_time: timestamp (nullable = true)\n",
      " |-- end_am_pm: string (nullable = true)\n",
      " |-- start_station_id: integer (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: float (nullable = true)\n",
      " |-- start_station_longitude: float (nullable = true)\n",
      " |-- end_station_id: integer (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: float (nullable = true)\n",
      " |-- end_station_longitude: float (nullable = true)\n",
      " |-- bike_id: integer (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- member_birth_year: integer (nullable = true)\n",
      " |-- member_gender: string (nullable = true)\n",
      " |-- pyment: string (nullable = true)\n",
      " |-- haversine_distance: string (nullable = true)\n",
      " |-- Diff_in_seconds: long (nullable = true)\n",
      " |-- Diff_in_minutes: double (nullable = true)\n",
      " |-- Trip_cost: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#assign timestamp to start_time and end_time\n",
    "#Calculate 'Diff_in_seconds' \n",
    "#Calculate 'Diff_in_minutes' \n",
    "#Calculate 'Trip_cost' \n",
    "df_pyspark=df_pyspark.withColumn('start_time',F.to_timestamp('start_time','HH:mm:ss'))\\\n",
    "    .withColumn('end_time',F.to_timestamp('end_time','HH:mm:ss'))\\\n",
    "    .withColumn('Diff_in_seconds',F.col('end_time').cast('long')-F.col('start_time').cast('long'))\\\n",
    "    .withColumn('Diff_in_minutes',(F.col('Diff_in_seconds')/60))\\\n",
    "    .withColumn('Trip_cost',(F.col('Diff_in_minutes')*0.35))\n",
    "\n",
    "df_pyspark.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[bike_id: int, sum_distance: double]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.groupBy(\"bike_id\")\\\n",
    "    .agg(F.sum(\"haversine_distance\").alias(\"sum_distance\")).sort(F.desc(\"sum_distance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/09 08:46:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: start time hour, start time minute, start time seconds, , end_time hour, end_time minute, end_time seconds, , start_station_id, start_station_name, start_station_latitude, start_station_longitude, end_station_id, end_station_name, end_station_latitude, end_station_longitude, bike_id, user_type, member_birth_year, member_gender, pyment\n",
      " Schema: start time hour, start time minute, start time seconds, _c4, end_time hour, end_time minute, end_time seconds, _c9, start_station_id, start_station_name, start_station_latitude, start_station_longitude, end_station_id, end_station_name, end_station_latitude, end_station_longitude, bike_id, user_type, member_birth_year, member_gender, pyment\n",
      "Expected: _c4 but found: \n",
      "CSV file: file:///workspaces/develhope-Data5-Team3/Data/2017-fordgobike-tripdataa.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark.write.option(\"header\",True).mode('overwrite').csv('/workspaces/develhope-Data5-Team3/Data/FordGoBike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
